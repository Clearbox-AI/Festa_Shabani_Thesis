# Addressing Gender and Racial Bias in AI: A Data-Centric Approach for Fairer Outcomes

This repository contains the code and resources used for my Master's thesis, *Addressing Gender and Racial Bias in AI: A Data-Centric Approach for Fairer Outcomes*. The work explores methods to mitigate gender and racial biases in AI systems using data-centric approaches.

## Project Overview

This project addresses the impact of biased datasets on AI model predictions, particularly in critical domains such as healthcare and socio-economics. The repository demonstrates:
- Bias Detection: Using fairness metrics like Statistical Parity Difference and Disparate Impact to measure bias.
- Bias Mitigation: Implementing preprocessing methods such as Reweighing, Disparate Impact Remover, Learning Fair Representations (LFR), and Optimized Preprocessing.
- Synthetic Data Augmentation: Generating synthetic data for underrepresented groups using Clearbox AI's Synthetic Kit.
- Evaluation: Assessing trade-offs between fairness and model performance using metrics like Balanced Accuracy and Disparate Impact.